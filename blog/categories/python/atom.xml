<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Python | 刘毅同学]]></title>
  <link href="http://liuyix.org/blog/categories/python/atom.xml" rel="self"/>
  <link href="http://liuyix.org/"/>
  <updated>2016-01-04T07:25:55+08:00</updated>
  <id>http://liuyix.org/</id>
  <author>
    <name><![CDATA[liuyix]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Python流式压缩和解压缩调研总结]]></title>
    <link href="http://liuyix.org/blog/2015/python-compress-stream/"/>
    <updated>2015-12-26T22:52:00+08:00</updated>
    <id>http://liuyix.org/blog/2015/python-compress-stream</id>
    <content type="html"><![CDATA[<p>最近两周在研究和实现了xtrabackup流式压缩上传&amp;下方案，这里做一下总结分享。</p>

<p>实现的效果是备份不在本地暂存，压缩内置到上传逻辑中，通过配置文件可以配置压缩细节，对上传使用者来讲是『无感知』的。利用压缩提高了上传效率和备份空间的使用率。</p>

<h2>压缩率和压缩性能的比较</h2>

<ul>
<li>lz4</li>
<li>gzip</li>
<li>lzop</li>
</ul>


<p>结论：在兼顾压缩率和压缩占用CPU资源以及压缩效率几个方面，最终选择了lzop。</p>

<p>lz4据说是压缩最快的算法，最终没有选择，有几个方面的原因：</p>

<ul>
<li>Python支持不完善，因为我的需求是<strong>流式</strong>的上传和下载，压缩源是一个tar stream，和压缩后的文件不会落在本地，而是直接上传到远端。</li>
<li>可运维性不高：lzo文件没有找到和gzip, lzop这样的命令行工具可以一个命令来对一个完整的lz4文件管理。当调用<code>file a.lz4</code> 显示的文件是data，这样就无法确认这个文件到底是否正确了。</li>
</ul>


<p>gzip给力的地方：</p>

<ul>
<li>gzip是目前应用最为广泛的格式了，看过很多压缩率评测的文章，gzip压缩率十分给力，在compresslevel是7到9时，压缩比很给力。</li>
<li>Python也是在standard library中支持gzip的压缩和解压缩。</li>
</ul>


<p>gzip不够给力的地方：</p>

<ul>
<li>压缩速度慢，在高压缩率上很慢。但是compress level在2~3时，gzip无论是压缩比还是压缩效率上都很有竞争优势</li>
<li>Python标准库gzip压缩对stream支持不够，流式压缩期望的方法是：传入一个fileobj，返回一个fileobj。而Gzip模块直接用的话是不支持这种方式的。</li>
</ul>


<p>然而gzip不足点是可以弥补的。
首先是压缩速度上，默认gzip是不支持并行化的压缩，最多只能有单核的性能，这是压缩性能的瓶颈。但是gzip是有其他工具支持<strong>并行压缩的</strong> —— <code>pigz</code>就是并行压缩版本的gzip，测试结果显示pigz可以充分利用多核并行化的性能，让压缩时间有明显的减少，当然代价就是load也会成倍的增长（24核机器上，我只测试了2~8个线程数）</p>

<p>其次是流式压缩可以通过Python轻松实现数据分块并行压缩。这里很重要的一点是：<strong>可以将每个数据分块看做一个独立文件压缩最终可以合成一个符合Gzip格式的压缩文件</strong>
简单的看了下的pigz的代码注释，发现pigz的原理也是这样子的。Python中使用生产者和消费者模式（生产者：一个线程专门来从数据源拉数据，数据存入Queue中，多个压缩进程负责压缩，把压缩后数据再放入到PriorityQueue按顺序组合成一个文件即可，当然也可以直接分块上传到远端服务器）。这也是我实现的第一个版本的流式压缩方案。这个方案主要的弱点在于内存资源占用比较大：无论是从数据源读取的原始数据块还是压缩后的压缩数据块，在最终写入/上传前都需要缓存在内存中。
在流式压缩上传的场景下，压缩上传的输出端是REST上传接口，因此并行压缩的内存占用上一定程度上受上传接口的性能影响。极端的情况，当上传速度很慢时，为了不影响压缩效率则需要在内存中开辟更大的内存buffer来放入等待压缩的数据块，这时就会占用到比较大的内存资源。不过也可以通过限制上传队列大小，在队列满的情况，数据源的<code>write</code>会阻塞等待。</p>

<p>我的第二个方案的是利用pigz外部工具在读取数据源前利用管道先接入到<code>pigz</code>，在从<code>pigz</code>直接读取到压缩后的数据流。这个方案算是最终方案的替代方案，之所以没有最终使用，原因在于和lzop相比，在压缩率相近的情况下，<code>pigz</code>消耗了更多的CPU资源。</p>

<p>对比方案：<code>pigz -p 2 -2</code> vs <code>lzop -c</code> ，即通过2线程压缩等级2和默认的lzop对比，前者压缩比可以高出10%，但是Load比后者高出了2倍不止，同时速度上也慢了25%。</p>

<p>lzop给力的地方：
实际测试中，lzop兼顾性能和压缩比同时压缩占用的CPU上是最平衡的。压缩速度稍慢于lz4，压缩比上可以达到gzip等级2~3的水平，同时cpu占用率和内存上比gzip低。</p>

<p>lzop不给力的地方：</p>

<ul>
<li>Python bindings 接口较少，不能直接用来流式压缩上传。

<ul>
<li>通过 <em>外挂</em> 方式也可以完成。（其实即使支持的好，也需要多进程来并行工作，和外挂差别不大）</li>
</ul>
</li>
</ul>


<h2>总结</h2>

<ul>
<li>lzop和pigz这两个压缩方案上在实际应用上都很有竞争力，只是我涉及的项目需求是生产环境上尽量不占用过多CPU，MEM资源，可以在压缩比上做妥协。因此选择了lzop。如果你在意CPU资源，更在乎压缩数据大小，则pigz是不错的选择。</li>
<li><em>外挂</em> 方式的数据压缩方案虽然集成上让Python程序有更多的外部依赖，但是考虑到Python本身并没有真正的线程的并行方案（你想要并行也要生成多个进程），其实资源占用区别不大。同时方案选型上也更加灵活。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[总结subprocess与pipe]]></title>
    <link href="http://liuyix.org/blog/2015/python-subprocess-pitfalls/"/>
    <updated>2015-12-23T21:31:00+08:00</updated>
    <id>http://liuyix.org/blog/2015/python-subprocess-pitfalls</id>
    <content type="html"><![CDATA[<h2>一、纠结的困境</h2>

<p>Python在多进程上不是很令人满意，尤其是<code>subprocess</code>模块。当用Python实现一个shell脚本中的管道时就出现了比较尴尬的局面。</p>

<h3>大数据量的管道问题</h3>

<p>subprocess模块有两种方式来和生成的子进程交互：<code>wait</code>和<code>communicate</code>。
关于<code>wait</code>文档中有以下说明：</p>

<blockquote><p>Warning This will deadlock when using stdout=PIPE and/or stderr=PIPE and the child process generates enough output to a pipe such that it blocks waiting for the OS pipe buffer to accept more data. Use communicate() to avoid that.</p></blockquote>

<p>即当stdout/stdin设置为PIPE时，使用<code>wait()</code>可能会导致死锁。因而建议使用<code>communicate</code></p>

<p>而对于<code>communicate</code>，文档又给出：</p>

<blockquote><p>Note The data read is buffered in memory, so do not use this method if the data size is large or unlimited.</p></blockquote>

<p><code>communicate</code>会把数据读入内存缓存下来，所以当数据很大或者是无限的数据时不要使用。</p>

<p>那么问题来了：当你要使用Python的<code>subprocess.Popen</code>实现命令行之间的管道传输，同时数据源又非常大（比如读取上GB的文本或者无尽的网络流）时，官方文档不建议用<code>wait</code>，同时<code>communicate</code>还可能把内存撑爆&hellip; <img src="/images/1.jpg" alt="/images/1.jpg" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Python并发实用编程手册[Draft]]]></title>
    <link href="http://liuyix.org/blog/2015/python-concurrent-programming/"/>
    <updated>2015-12-17T07:08:00+08:00</updated>
    <id>http://liuyix.org/blog/2015/python-concurrent-programming</id>
    <content type="html"><![CDATA[<p>Python并发编程<del>常用的</del>builtin就是2个模块：<code>threading</code>和<code>multiprocessing</code>。其中<code>threading</code>因为著名的GIL，实际是<em>伪多线程</em>，每个thread并没有对应一个pthread；<code>multiprocessing</code>则是利用多进程的手段来绕过GIL达到并发的效果。</p>

<p>如果你的任务并非是CPU密集型，而是IO密集型或者网络应用的话——单线程时CPU总是处于等待的状态时，用threading其实影响不大。</p>

<!--more-->


<h2>threading</h2>

<p>Doc: <a href="https://docs.python.org/2/library/threading.html">https://docs.python.org/2/library/threading.html</a></p>

<h3>Thread</h3>

<p>和其他语言的线程创建类似，有两种方式创建线程的方式，一种是创建thread时传入要执行的工作方法，另外一种是创建<code>Thread</code>的子类。</p>

<h4>join</h4>

<p><code>join()</code> 方法提供了不同线程间的协同功能。通常的用法是主线程在创建完所有的工作线程后，循坏调用没有工作线程的<code>join()</code>方法来等待所有线程的结束。<code>join()</code>方法还可以增加<code>timeout</code>参数设置超时时间，可以用来避免一个工作线程出问题使得整个程序死等的情况。</p>

<h4>daemon</h4>

<p><code>daemon</code>是Thread的一个属性，程序退出不关心设置了<code>daemon</code>线程的『死活』。即只要所有非<code>daemon</code>线程都结束了，那么程序就可以结束掉了。
<code>daemon</code>线程类似于程序内部的『后台服务』，提供了程序运行时的『基础设施』，而不是程序工作流程链路中的部分。</p>

<h2>Lock, RLock</h2>

<p>并发编程中，锁是基本原语。当有共享资源需要『互斥』访问时就要用锁来对这些资源进行保护。<del>然而Python语言中由于GIL问题，实际上builtin的数据类型都是thread-safe的，使用时无需上锁</del>对于mutable类型的变量在多线程共享使用时应该用Lock来控制并发，不能依赖Python的具体实现。</p>

<p>在Python 2.6以上，可以使用<code>with</code>简化获取和释放锁的过程，让代码更加简洁。</p>

<h2>Condition</h2>

<p>是对Lock的一层封装。提供了<code>acquire()</code>, <code>release()</code>这两个Lock原语，还提供了<code>wait()</code>, <code>notify()</code>, <code>notifyAll()</code>这三个接口。</p>

<ul>
<li><code>wait()</code> 是获得锁的线程主动释放锁，转入等待过程。</li>
<li><code>notify()</code> 是获得锁的一方不释放锁，但是会唤醒等待这把锁的其中一个线程。</li>
<li><code>notifyAll()</code> 类似<code>notify()</code>，不同的是不是唤醒一个，而是唤醒所有等待锁的线程。</li>
</ul>


<p>典型的使用场景是生产者消费者模式。一个生产者，若干个消费者用一个队列来交互，这时候每个工作线程要想工作首先都需要尝试获得队列的锁。当一个消费者拿到了锁可以访问队列时发现队列时空的，这时候就要使用<code>wait()</code>来主动释放这把锁，然后将自己放到等待线程列表中等待；当一个生产者获得了队列的锁时，将数据放入到队列中，同时在释放锁之前调用<code>notify()</code>来通知其他等待这把锁的线程：『达令，有你快递儿~』，然后在释放锁。如果生产了多个数据，那么就可以使用<code>notifyAll()</code>通知所有的等待线程。</p>

<h2>Event</h2>

<p>Event接口非常简单，就是<code>is_set()</code>和<code>set()</code>, Event用于在多线程间共享某一事件是否发生。我经常用来创建一个<code>stop_event</code>传给所有的worker线程，这样如果程序遇到异常或者其他需要终止的条件时，只要<code>stop_event.set()</code>，其他工作线程会循环的检查<code>stop_event.is_set()</code>。</p>

<h2>Semphore</h2>

<p>上过操作系统课程的同学对『信号量』都有过接触，信号量和对应的<code>p</code>, <code>v</code>操作是并发程序的『操作原语』，即用这两个操作就可以表示所有的并发程序的设计和实现了。上述的Lock, Condition都可以看做是信号量的特定形式。</p>

<p>信号量由一个内部计数器和两个接口构成，内部的计数是非负数，对计数的操作：<code>release()</code>用于增加计数，<code>acquire()</code>用于减计数器。当计数器减到0时，<code>release()</code>操作就会阻塞直至其他工作线程完成<code>acquire()</code>。</p>

<p>Python的<code>acquire()</code>还支持可选参数<code>blocking</code>，当设置为True且计数器为0时，则会阻塞等待。</p>

<blockquote><p>前面的叙述都算是对基本内容的解读，干货现在开始。</p></blockquote>

<h2>如何优雅的中断其他线程的任务</h2>

<h3>使用Event</h3>

<p>在每个线程创建时传入<code>stop_event</code>,遇到异常或者到程序需要结束的时候，则<code>stop_event.set()</code>就可以了。
缺点：只有在线程完成一次工作后才会检查stop_event一次。因此如果线程工作比较久时会设置了<code>stop_event</code>也不会立刻结束。</p>

<p>```python</p>

<h1>worker</h1>

<p>def do_some_job(job_q, stop_event):</p>

<pre><code>while not stop_event.is_set():
    try:
        do_foo()
    except:
        stop_event.set()
</code></pre>

<h1>manager</h1>

<p>import Queue
thread_count = 4
stop_event = threading.Event()
job_queue = Queue.Queue()</p>

<p>threads = [threading.Thread(target=do_some_job, args=(job_queue, stop_event,)) for i in xrange(thread_count)]</p>

<p>for thr in threads:</p>

<pre><code>thr.start()
</code></pre>

<p>for thr in threads:</p>

<pre><code>thr.join()
</code></pre>

<p>```</p>

<h2>Signal的处理</h2>

<p>多线程中Signal只能由<strong>主线程</strong>处理Signal。这部分还没有搞过，暂时略过。</p>

<ul>
<li><a href="https://pymotw.com/2/signal/#signals-and-threads">https://pymotw.com/2/signal/#signals-and-threads</a></li>
<li><a href="http://stackoverflow.com/questions/25676835/signal-handling-in-multi-threaded-python">http://stackoverflow.com/questions/25676835/signal-handling-in-multi-threaded-python</a></li>
<li><a href="https://docs.python.org/2/library/signal.html">https://docs.python.org/2/library/signal.html</a></li>
</ul>


<h2>multiprocessing &ndash; Process-based “threading” interface.</h2>

<p>多进程方式实现threading的接口，从而真正的达到并发。对于计算密集型的应用来说，利用<code>multiprocessing</code>模块可以用Python释放<em>真¤多核</em>性能。</p>

<p>多线程的弊端：多进程相比单进程会有独立的内存地址空间，因此无法共享同父进程的资源，进程切换的系统开销会比多线程多。同时进程间的交互、资源共享也比较复杂和『耗能』。</p>

<h2>Python并发常见编程模式 &mdash; 生产者消费者模式</h2>

<ul>
<li>使用<code>multiprocessing.Queue</code>来进行数据交互</li>
<li>使用<code>multiprocessing.Event</code>来交互事件信号</li>
</ul>


<h2>Python并发常见编程模式 &mdash; Pool + map</h2>

<p>TODO</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docopt -- Python必备的命令行接口模块]]></title>
    <link href="http://liuyix.org/blog/2015/python-docopt/"/>
    <updated>2015-10-21T00:02:00+08:00</updated>
    <id>http://liuyix.org/blog/2015/python-docopt</id>
    <content type="html"><![CDATA[<p>docopt很适合经常需要用python写命令行工具的同学使用。</p>

<h2>docopt之前</h2>

<p>工作需要，经常会用大块的代码来定(ren)义(rou)命令行界面的工具。代码经常是如下的样子：</p>

<p>```python</p>

<p>import optparse</p>

<p>parser = optparse.OptionParser()
parser.add_option(&lsquo;&mdash;foo&rsquo;, &lsquo;-f&rsquo;, default=&lsquo;1&rsquo;, type=&lsquo;int&rsquo;)
parser.add_option(&lsquo;&mdash;bar&rsquo;, &lsquo;-b&rsquo;, action=&lsquo;store_true&rsquo;)</p>

<h1>类似以上的代码大概几十行</h1>

<p>opts, args = parser.parse_args()</p>

<p>```</p>

<p>每一个python脚本都需要提供类似的接口。因此每一次都需要写类似的代码。在写过几次后为了保持DRY原则，我将初始化parser封装为一个method放在util部分。可是依旧是逃不过重复的写<code>parser.add_option</code>。不止一次地我考虑干脆自己写个模板类，以后命令行的定义直接以配置文件的形式写出来，然后每次都通过读取这个配置文件自动化的去生成parser。我相信这个问题我一定不是第一个遇到，应该会有已知的模块解决这个laber intensive的工作。</p>

<p>正在这个时候，偶然看到Python weekly发现了docopt</p>

<h2>docopt</h2>

<p>docopt官网地址：<a href="http://docopt.org/">http://docopt.org/</a></p>

<p>docopt的作者有一个30分钟的视频很好的介绍了docopt这个moudule。推荐大家看一下，自备梯子~ <a href="https://youtu.be/pXhcPJK5cMc">https://youtu.be/pXhcPJK5cMc</a></p>

<p>更令懒人们惊喜的是作者还制作了一个js版本的docopt，可以让你在浏览器中把玩docopt： <a href="http://try.docopt.org/">http://try.docopt.org/</a></p>

<p>使用docopt后，代码上会更加Pythonic，具有很高的可读性，命令行接口的定义所见即所得的样式：</p>

<p>```</p>

<h1>docopt example</h1>

<p>mydoc = &ldquo;&rdquo;&ldquo;Naval Fate.</p>

<p>Usage:
  naval_fate.py ship new <name>&hellip;
  naval_fate.py ship <name> move <x> <y> [&mdash;speed=<kn>]
  naval_fate.py ship shoot <x> <y>
  naval_fate.py mine (set|remove) <x> <y> [&mdash;moored|&mdash;drifting]
  naval_fate.py -h | &mdash;help
  naval_fate.py &mdash;version</p>

<p>Options:
  -h &mdash;help     Show this screen.
  &mdash;version     Show version.
  &mdash;speed=<kn>  Speed in knots [default: 10].
  &mdash;moored      Moored (anchored) mine.
  &mdash;drifting    Drifting mine.
&ldquo;&rdquo;"</p>

<p>from docopt import docopt</p>

<p>arguments = docopt(mydoc, version=&lsquo;0.1&rsquo;)</p>

<p>print arguments
```</p>

<p>这样就定义了一个丰富的命令行接口。命令行接口提供了<code>--help</code>和<code>--version</code>两个基础功能。其中<code>--help</code>输出<code>mydoc</code>，<code>--version</code>输出指定的<code>version</code>信息。</p>

<p>接口还提供了2个参数（ship, mine），每种参数还提供了不同的几种参数的组合。其中<code>[...]</code>内是可选参数，<code>(...|...)</code>是互斥参数。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[由互联网中的Python应用想到的网站架构的优化]]></title>
    <link href="http://liuyix.org/blog/2015/python-in-industry/"/>
    <updated>2015-04-08T22:56:00+08:00</updated>
    <id>http://liuyix.org/blog/2015/python-in-industry</id>
    <content type="html"><![CDATA[<ul>
<li>国内<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>

<ul>
<li>知乎</li>
<li>豆瓣</li>
<li>果壳网</li>
</ul>
</li>
<li>国外，只列出我认识的比较出名的，还有好多<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>=。=

<ul>
<li>Quora 国外的知乎？</li>
<li>Dropbox 国外的金山快盘？</li>
<li>Disqus 国外的多说？</li>
<li>Pinterest 国外的花瓣？</li>
<li>Youtube 国外的优酷？</li>
<li>Slideshare 国外的百度文库？</li>
<li>reddit 国外的猫扑？</li>
<li>Yelp 国外的大众点评</li>
<li>&hellip;</li>
</ul>
</li>
</ul>


<p>更多的信息可以参考Python官网的<a href="https://www.python.org/about/success/">Python Success Stories</a>。</p>

<h3>Quora</h3>

<p>下面是QuorWhy did Quora choose Python for its development?a创始人在Quora上对<em>Why did Quora choose Python for its development?</em>的回答<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>

<blockquote><p>We decided that Python was fast enough for most of what we need to do (since we push our performance-critical code to backend servers written in C++ whenever possible). As far as typechecking, we ended up writing very thorough unit tests which are worth writing anyway, and achieve most of the same goals.</p></blockquote>

<p>可以看到对于Python的性能短板，Quora在performance-critical的地方尽可能换用了C++。对于Python没有静态类型，Quora用尽可能的单元测试来确保质量。之所以选择Python其实很大的原因是Founder对Python比较擅长。
进一步google了下，他们的框架用的Pylon。</p>

<h3>知乎的技术架构</h3>

<p>知乎CTO在去年年底有过分享，目前在InfoQ上能找到整理稿。链接：<a href="http://www.infoq.com/cn/news/2014/12/zhihu-architecture-evolution">http://www.infoq.com/cn/news/2014/12/zhihu-architecture-evolution</a></p>

<p>简而言之用的tornado，自己开发了日志系统Kids，消息传递系统Sink，还有页面渲染ZhihuNode。</p>

<h3>网站架构及性能的思考</h3>

<p>本周听了一次FB周海平在阿里内部的一次分享。无论是阿里、Facebook还是豆瓣，我发现了在网站架构上这几家有很多共同点的：</p>

<ul>
<li>MySQL作为存储后端</li>
<li>MySQL上一定有memcache、tair这样的KV系统做缓存</li>
<li>都各自开发了适合自己的消息分发系统，Notify, Thrift, Beanstalkd</li>
<li>后端应该都具有实时日志数据分析： HBase、云梯2、Kids</li>
<li>不同程度上用异步化来提高性能，并会一直以此来作为性能提升的方法。</li>
<li>消息链路上的优化：一个网页的渲染上是树状结构的获取数据，因此可以在通过优化这棵树来达到优化整个过程的目的</li>
</ul>


<h3>其他</h3>

<p>网站选型不单纯是比较语言优劣，还和社区的发展趋势活跃(谁都不想用过一门可能几年就无人问津的语言)、团队内普遍的好恶和掌控能力（C、C++最好，但是大家都不会）、整个行业的形势（团队内都用Lisp，但是招不到人）等等多种因素有关系。
选择哪门语言确实重要，这决定了未来几年或者更远的时间内技术的发展路线，更重要的当规模扩大后需要在性能优化上要付出的代价。（这里面可以拿Facebook优化PHP作为反例，若是当初扎克用的是java或者c++，也许也不会因此如此兴师动众的重写了PHP生态系统里面的大部分东西。）</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p><a href="http://www.zhihu.com/question/19685768">知乎-国内使用 Python 作为主要开发语言的知名网站有哪些</a><a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p><a href="http://www.quora.com/Which-Internet-companies-use-Python">Quora-Which Internet companies use Python?</a><a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p><a href="http://www.quora.com/Why-did-Quora-choose-Python-for-its-development">Quora-Why did Quora choose Python for its development?</a><a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
